---
title: "HW 6"
author: "Kelly Wang"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(leaps)
library(MASS)
library(tidyverse)
library(modelr)
library(mgcv)
library(p8105.datasets)
library(rnoaa)


```

## Problem 1
```{r import_data}
# load the data in
birthweight_data=
  read_csv(file= "./data/birthweight.csv") 

#tidy data
birthweight_tidy = 
  birthweight_data%>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(
    babysex=recode(babysex, '1'= 'male', '2'='female'),
    babysex=as.factor(babysex),
    babysex=fct_relevel(babysex,"male", "female"),
    bhead=as.numeric(bhead),
    blength=as.numeric(blength),
    bwt=as.numeric(bwt),
    delwt=as.numeric(delwt),
    fincome=as.numeric(fincome), 
    frace=recode(frace, '1'='White', '2'= 'Black', '3'='Asian', '4'='Puerto Rican', '8'='Other', '9'='Unknown'),
    frace=as.factor(frace),
    frace=fct_relevel(frace,"White", "Black", "Asian", "Puerto Rican", "Other", "unknown"),
    gaweeks=as.numeric(gaweeks),
    malform=recode(malform, '0' = "absent", '1' = "present"),
    malform=as.factor(malform),
    malform=fct_relevel(malform, "absent", "present"),
    menarche=as.numeric(menarche),
    mheight=as.numeric(mheight),
    momage=as.numeric(momage),
    mrace=recode(mrace,'1' = 'White', '2' = 'Black', '3' = 'Asian', '4' = 'Puerto Rican', ' 8' = 'Other'),
    mrace=as.factor(mrace),
    parity=as.numeric(parity), 
    pnumlbw=as.numeric(pnumlbw),
    pnumsga=as.numeric(pnumsga),
    ppbmi = as.numeric(ppbmi),
    ppwt=as.numeric(ppwt),
    smoken=as.numeric(smoken),
    wtgain=as.numeric(wtgain)
  )
```

#### Model Fitting

This is my model fitting process: 

1. Tidy the data
2. Use a Stepwise function to fit the model
3. Create the model 
4. Test for residuals/goodness of fit test
5. Comparing it to the other models 
```{r}
#set seed for reproducibility
set.seed(10)
#fit the full model

fit= lm(bwt ~ ., data=birthweight_tidy) %>% 
  stepAIC(direction="both", trace=FALSE)

#Variables selected: babysex, bhead, blength, delwt, fincome, gaweeks, mheight, mrace, parity, ppwt, smoken
a= fit %>% broom::glance()

##adjusted R^2 0.71725 --> pretty good!

b= fit %>% broom::tidy()

# Step 4. Running regression diagnostics
predictions =modelr::add_predictions(birthweight_tidy, fit)

residuals_plot=
  predictions %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x=pred, y=resid)) + geom_point()+
  labs(x= "Prediction", y = "Residual", title="Residual by Prediction")

residuals_plot
```
```{r comparing}
#Model 1
model1_lm=lm(bwt ~ blength + gaweeks, data=birthweight_tidy) %>% 
  broom::tidy()

#model 2:
model2_lm=lm(bwt~ bhead + blength + babysex + bhead*blength +bhead*babysex + blength*babysex + blength*babysex*bhead, data=birthweight_tidy ) %>% 
  broom::tidy()

##found out a shortcut during office hours to do this
model21_lm=lm(bwt~ bhead*blength*babysex, data=birthweight_tidy ) %>% 
  broom::tidy()

# ploting three models to see best model
cv_df=
  crossv_mc(birthweight_tidy, 100) %>% 
  mutate(
    train=map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df=
  cv_df %>% 
  mutate(fit = map(train, ~lm(bwt ~ ., data=.x) %>% stepAIC(direction="both", trace=FALSE)),
        model1_lm= map(train, ~lm(bwt ~ blength + gaweeks, data=.x)),
        model2_lm=map(train, ~lm(bwt~ bhead + blength + babysex + bhead*blength +bhead*babysex + blength*babysex + blength*babysex*bhead, data=.x))) %>% 
  mutate(rmse_fit = map2_dbl(fit, test, ~rmse(model=.x, data=.y)),
         rmse_model1= map2_dbl(model1_lm, test, ~rmse(model=.x, data=.y)),
         rmse_model2= map2_dbl(model2_lm, test, ~rmse(model=.x, data=.y)))
```


```{r violinplots}
cv_df %>% 
pivot_longer(
    rmse_fit:rmse_model2,
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

As listed above, these were my steps to creating a model. 

First I tidied the data--which included `r nrow(birthweight_tidy)` participants and `r ncol(birthweight_tidy)` variables--to make sure that all variables that were numeric were coded as numeric, and all categorical variables became factored variables. 

Afterwards, I used an automated stepwise fuction to generate a model of interest. This was using the `stepAIC()` function that is part of the ` library(MASS)` package. From there, a model was generated to include the following variables: `babysex`,  `bhead` , `blength` , `delwt`, `fincome`, `gaweeks`, `mheight`, `mrace`, `parity`, `ppwt`, and `smoken`. The following is my model: 


Next, I created a ggplot of the predicted values to the residual. As seen from the plot, majority of the plots center around the residual=0, which is very ideal.

Looking at these graphs, my model, labeled "fit" appears to have the best fitting model as it has the lowest rsme value.
birthweight = β0 + β1*babysex + β2*bhead + β3*blength + β4*delwt + β5*fincome + β6*gaweeks + β7*mheight + β8*mrace + β9*parity + β10*ppwt + β11*smoken


## Problem 2
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  dplyr::select(name, id, everything() )

## i had to add "dplyr":: because the original code was not running without it
```
```{r}
#for estimated r^2
set.seed(1)
bootstrap_rsquared=
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>% 
  select(results) %>% 
  unnest(results) 
bootstrap_rsquared_plot=
  bootstrap_rsquared %>% 
  ggplot(aes(x = r.squared)) + geom_density()

quantile(pull(bootstrap_rsquared, r.squared), probs=0.025)
quantile(pull(bootstrap_rsquared, r.squared), probs=0.975)

print(bootstrap_rsquared_plot)
```

```{r}
set.seed(1)
bootstrap_log=
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(results, .id) %>% 
  unnest(results) %>%
  select(.id, estimate, term) %>% 
  pivot_wider(
    names_from="term",
    values_from="estimate"
  ) %>% 
  janitor::clean_names() %>% 
  mutate(
    lg=log(intercept*tmin)
  ) 

bootstrap_log_plot=
  bootstrap_log %>% 
  ggplot(aes(x = lg))+ geom_density()

quantile(pull(bootstrap_log, lg), probs=0.025)
quantile(pull(bootstrap_log, lg), probs=0.975)

print(bootstrap_log_plot)

```

Using the NOAA weather dataset that we have previously used in our class, which has `r nrow(weather_df)` rows and `r ncol(weather_df)` columns, 5000 bootstrap samples were used to produce estimates of the r^2 value and of log(β0^2*β1^2) 

In our model, r^2 , we are 95% confident that our true r^2 value lies between `r quantile(pull(bootstrap_rsquared, r.squared), probs=0.025)` and `r quantile(pull(bootstrap_rsquared, r.squared), probs=0.975)`. Also, we are 95% confident that the true log(β0^2xβ1^2) lies between `r quantile(pull(bootstrap_log, lg), probs=0.025)` and `r quantile(pull(bootstrap_log, lg), probs=0.975)`. As seen here, our r^2 distributions has a right skewed distribution. However, our log(β^2xβ1^2) distribution looks more normal, which would make sense as we usually use the log transformation to make skewed distribution more normal. 

